{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7dpvKpUEMWB7hp+Dpsvky"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Libraries"],"metadata":{"id":"sGn5EtCg-9d_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbHGvG8V-F5p"},"outputs":[],"source":["import numpy as np\n","import torch\n","import math\n","from cvxopt import matrix, solvers\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from sklearn.datasets import load_iris\n","\n"]},{"cell_type":"markdown","source":["## Data classes"],"metadata":{"id":"V4nRq9Uq-_Tv"}},{"cell_type":"code","source":["class X_values:\n","    def __init__(self, dataset):\n","        self.feature_dim = dataset.shape[1]\n","        self.data_size = dataset.shape[0]\n","        self.tensor_form = torch.tensor(dataset, dtype=torch.float32)\n","        print(f\"X_values created successfully with dimensions {self.tensor_form.shape}, feature_dim: {self.feature_dim}, data_size: {self.data_size}\")\n","\n","class Y_values:\n","    def __init__(self, targets):\n","        self.data_size = targets.shape[0]\n","        self.tensor_form = torch.tensor(targets, dtype=torch.float32)\n","        print(f\"Y_values created successfully with dimensions {self.tensor_form.shape}\")\n","\n","\n","class Dataset: # !! Use your classes while constructing an instance !!\n","    def __init__(self, x_values, y_values):\n","        self.x_tensor = x_values.tensor_form\n","        self.y_tensor = y_values.tensor_form\n","\n","        if self.x_tensor.shape[0] != self.y_tensor.shape[0]:\n","            raise ValueError(\"Mismatch between X and y dimensions\")\n","\n","        self.feature_dim = x_values.feature_dim\n","        self.data_size = x_values.data_size\n","\n","        print(f\"Dataset created with X: {self.x_tensor.shape}, Y: {self.y_tensor.shape}\")\n"],"metadata":{"id":"BTE3xsj6-_Z2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Related functions & Kernels"],"metadata":{"id":"L3dRS-oi-_gI"}},{"cell_type":"code","source":["def split_dataset(dataset, train_rate, val_rate, test_rate):\n","    if abs(train_rate + val_rate + test_rate - 1.0) > 1e-6:\n","        raise ValueError(\"Split rates must sum to 1\")\n","\n","    total_size = dataset.x_tensor.shape[0]\n","    train_size = int(total_size * train_rate)\n","    val_size = int(total_size * val_rate)\n","\n","    indices = torch.randperm(total_size)\n","    train_indices = indices[:train_size]\n","    val_indices = indices[train_size:train_size + val_size]\n","    test_indices = indices[train_size + val_size:]\n","\n","    x_train, y_train = dataset.x_tensor[train_indices], dataset.y_tensor[train_indices]\n","    x_val, y_val = dataset.x_tensor[val_indices], dataset.y_tensor[val_indices]\n","    x_test, y_test = dataset.x_tensor[test_indices], dataset.y_tensor[test_indices]\n","\n","    train_dataset = Dataset(X_values(x_train.numpy()), Y_values(y_train.numpy()))\n","    val_dataset = Dataset(X_values(x_val.numpy()), Y_values(y_val.numpy()))\n","    test_dataset = Dataset(X_values(x_test.numpy()), Y_values(y_test.numpy()))\n","\n","    return train_dataset, val_dataset, test_dataset\n","\n","# RBF Kernel Calculator (straightforward)\n","# (some accelerating/probablistic appraoches are possible, can be implemented in case of such a requirement)\n","def rbf_kernel(vec_x, vec_y, sigma=1):\n","    # Assume our vec_x and vec_y are 1-dim torch tensors (vectors), write below in torchized form\n","    return torch.exp(-(vec_x - vec_y)**2 / (2 * sigma**2))\n","\n","def polynomial_kernel(vec_x, vec_y, bias=1, deg=3):\n","  # Assume our vec_x and vec_y are 1-dim torch tensors (vectors), write below in torchized form\n","  return ((torch.mul(vec_x, vec_y) + bias)**deg)\n","\n","\n","\n","def rbf_feature_transform(vec_x, sigma=1, expansion_term=4):\n","    fi_vec_x = []  # Initialize transformed feature vector\n","\n","    for x_i in vec_x:\n","        # Compute each feature transformation term\n","        transformed_value = (\n","            math.exp(-(x_i**2) / (2 * sigma**2))  # Exponential decay\n","            * (1 / (math.sqrt(math.factorial(expansion_term)) * sigma**expansion_term))  # Scaling\n","            * x_i**expansion_term  # Power of the input\n","        )\n","        fi_vec_x.append(transformed_value)  # Append to the feature vector\n","\n","    return fi_vec_x\n","\n","\n","\n","\n","\n"],"metadata":{"id":"3kGgpnju-_mX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## SVM Model by Scratch (for now, without kernel)"],"metadata":{"id":"thhTxXCf-_r-"}},{"cell_type":"code","source":["def svm_dual_qp(X_tensor, y_tensor, C=1):\n","    X = X_tensor.numpy().astype(np.float64)  # Ensure float64\n","    y = y_tensor.numpy().astype(np.float64)  # Ensure float64\n","    N = X.shape[0]\n","\n","    # Compute the kernel matrix (linear kernel)\n","    K = np.dot(X, X.T)\n","\n","    # Construct QP parameters\n","    P = matrix(np.outer(y, y) * K)  # Q = y_n * y_m * dot_product(x_n, x_m)\n","    q = matrix(-np.ones(N))         # Linear term: -1 * sum(alpha_n)\n","    G = matrix(np.vstack((-np.eye(N), np.eye(N))))  # Inequality: -alpha <= 0 and alpha <= C\n","    h = matrix(np.hstack((np.zeros(N), np.ones(N) * C)))  # Bounds: 0 <= alpha <= C\n","    A = matrix(y.reshape(1, -1))   # Equality: sum(y_n * alpha_n) = 0\n","    b = matrix(0.0)\n","\n","    # Solve QP problem\n","    solution = solvers.qp(P, q, G, h, A, b)\n","\n","    # Extract alpha values\n","    alphas = np.ravel(solution['x'])\n","    return torch.tensor(alphas, dtype=torch.float32)"],"metadata":{"id":"CAtFZC0a-_yy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Testing function (Scratch)"],"metadata":{"id":"5oZ0sqWjQqGW"}},{"cell_type":"code","source":["# Test the implementation using Iris dataset\n","def test_svm_dual_qp():\n","    # Load Iris dataset (binary classification: classes 0 and 1)\n","    iris = datasets.load_iris()\n","    X = iris.data[iris.target != 2]  # Select only class 0 and 1\n","    y = iris.target[iris.target != 2]\n","    y = np.where(y == 0, -1, 1)      # Convert labels to -1 and 1\n","\n","    # Standardize the dataset\n","    scaler = StandardScaler()\n","    X = scaler.fit_transform(X)\n","\n","    # Split the dataset\n","    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    print(f\"ATTENTION: number of data: {len(x_train)}, number of features: {len(x_train[0])}\")\n","\n","    # Create dataset objects\n","    train_dataset = Dataset(X_values(x_train), Y_values(y_train))\n","    test_dataset = Dataset(X_values(x_test), Y_values(y_test))\n","\n","    # Train SVM using dual QP\n","    alphas = svm_dual_qp(train_dataset.x_tensor, train_dataset.y_tensor)\n","\n","    # Identify support vectors\n","    support_vector_indices = torch.where(alphas > 1e-5)[0]\n","    print(\"Support vectors:\", train_dataset.x_tensor[support_vector_indices])\n","\n","    # Calculate weight vector and bias\n","    w = torch.sum(alphas[support_vector_indices][:, None] * train_dataset.y_tensor[support_vector_indices][:, None] * train_dataset.x_tensor[support_vector_indices], dim=0)\n","    b = train_dataset.y_tensor[support_vector_indices][0] - torch.dot(w, train_dataset.x_tensor[support_vector_indices][0])\n","\n","    print(\"Weight vector (w):\", w)\n","    print(\"Bias (b):\", b)"],"metadata":{"id":"y0ekdc0XQqKO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Scikit-learn SVM Model"],"metadata":{"id":"VR9PnrH-D5nN"}},{"cell_type":"code","source":["def train_svm_with_sklearn():\n","    # Load the Iris dataset\n","    iris = load_iris()\n","    X = iris.data[iris.target != 2]  # Select only class 0 and 1 for binary classification\n","    y = iris.target[iris.target != 2]\n","    y = np.where(y == 0, -1, 1)  # Convert labels to -1 and 1\n","\n","    # Standardize the dataset\n","    scaler = StandardScaler()\n","    X = scaler.fit_transform(X)\n","\n","    # Split the dataset into train and test sets\n","    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Create dataset objects using your classes\n","    train_dataset = Dataset(X_values(x_train), Y_values(y_train))\n","    test_dataset = Dataset(X_values(x_test), Y_values(y_test))\n","\n","    # Train an SVM model using Scikit-Learn\n","    svm_model = SVC(kernel='linear', C=1.0)  # Linear kernel and penalty parameter C=1.0\n","    svm_model.fit(train_dataset.x_tensor.numpy(), train_dataset.y_tensor.numpy())\n","\n","    # Make predictions on the test dataset\n","    y_pred = svm_model.predict(test_dataset.x_tensor.numpy())\n","\n","    # Evaluate the model\n","    accuracy = accuracy_score(test_dataset.y_tensor.numpy(), y_pred)\n","    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","\n","    # Print support vectors\n","    print(f\"Support vectors:\\n{svm_model.support_vectors_}\")\n","\n","    # Print model parameters\n","    print(f\"Weights (w): {svm_model.coef_}\")\n","    print(f\"Bias (b): {svm_model.intercept_}\")"],"metadata":{"id":"shxnNs6gD5s-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Running the code"],"metadata":{"id":"xTPE45CVC0nt"}},{"cell_type":"code","source":["# Run the test\n","print(\"/////////////////////////\")\n","print(\"!! SCRATCH MODEL !!\")\n","print(\"/////////////////////////\")\n","print()\n","test_svm_dual_qp()\n","print()\n","\n","# Run the training and testing function\n","print(\"/////////////////////////\")\n","print(\"!! LIBRARY MODEL !!\")\n","print(\"/////////////////////////\")\n","print()\n","train_svm_with_sklearn()\n","print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uf8Mi6iCC0t4","executionInfo":{"status":"ok","timestamp":1734027885746,"user_tz":-180,"elapsed":251,"user":{"displayName":"Yusuf Kagan Cicekdag","userId":"15277042035745322572"}},"outputId":"56b827c8-e421-4195-91eb-ac05f616307e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/////////////////////////\n","!! SCRATCH MODEL !!\n","/////////////////////////\n","\n","ATTENTION: number of data: 80, number of features: 4\n","X_values created successfully with dimensions torch.Size([80, 4]), feature_dim: 4, data_size: 80\n","Y_values created successfully with dimensions torch.Size([80])\n","Dataset created with X: torch.Size([80, 4]), Y: torch.Size([80])\n","X_values created successfully with dimensions torch.Size([20, 4]), feature_dim: 4, data_size: 20\n","Y_values created successfully with dimensions torch.Size([20])\n","Dataset created with X: torch.Size([20, 4]), Y: torch.Size([20])\n","     pcost       dcost       gap    pres   dres\n"," 0: -2.8349e+00 -1.1910e+02  6e+02  2e+00  1e-15\n"," 1: -1.0131e+00 -5.2457e+01  8e+01  2e-01  1e-15\n"," 2:  1.6941e-01 -6.7916e+00  9e+00  2e-02  2e-15\n"," 3: -2.3732e-01 -8.6162e-01  6e-01  2e-04  8e-16\n"," 4: -4.7377e-01 -6.8358e-01  2e-01  4e-05  5e-16\n"," 5: -5.8384e-01 -6.6509e-01  8e-02  3e-06  5e-16\n"," 6: -6.1841e-01 -6.1991e-01  2e-03  5e-08  5e-16\n"," 7: -6.1902e-01 -6.1904e-01  2e-05  5e-10  4e-16\n"," 8: -6.1903e-01 -6.1903e-01  2e-07  5e-12  5e-16\n","Optimal solution found.\n","Support vectors: tensor([[-1.5208, -1.6774, -1.0823, -0.8643],\n","        [-0.5811, -1.2575,  0.0964,  0.5584],\n","        [-0.8943, -1.4674,  0.3044,  0.3806],\n","        [-0.5811,  0.4220, -0.8050, -0.5086]])\n","Weight vector (w): tensor([ 0.2671, -0.3390,  0.7005,  0.7490])\n","Bias (b): tensor(0.2431)\n","\n","/////////////////////////\n","!! LIBRARY MODEL !!\n","/////////////////////////\n","\n","X_values created successfully with dimensions torch.Size([80, 4]), feature_dim: 4, data_size: 80\n","Y_values created successfully with dimensions torch.Size([80])\n","Dataset created with X: torch.Size([80, 4]), Y: torch.Size([80])\n","X_values created successfully with dimensions torch.Size([20, 4]), feature_dim: 4, data_size: 20\n","Y_values created successfully with dimensions torch.Size([20])\n","Dataset created with X: torch.Size([20, 4]), Y: torch.Size([20])\n","Test Accuracy: 100.00%\n","Support vectors:\n","[[-1.52079511 -1.67737627 -1.08231223 -0.86427629]\n"," [-0.58106589  0.42196825 -0.80497402 -0.50860703]\n"," [-0.58106589 -1.25750732  0.09637501  0.55840069]\n"," [-0.89430898 -1.4674418   0.30437863  0.38056609]]\n","Weights (w): [[ 0.26755937 -0.33942664  0.6996968   0.7493304 ]]\n","Bias (b): [0.24283818]\n","\n"]}]}]}