{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9736c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2ca7356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_values created with dimensions torch.Size([300, 10])\n",
      "Y_values created with dimensions torch.Size([300, 1])\n",
      "Dataset created with X: torch.Size([300, 10]), Y: torch.Size([300, 1])\n",
      "X_values created with dimensions torch.Size([210, 10])\n",
      "Y_values created with dimensions torch.Size([210, 1])\n",
      "Dataset created with X: torch.Size([210, 10]), Y: torch.Size([210, 1])\n",
      "X_values created with dimensions torch.Size([60, 10])\n",
      "Y_values created with dimensions torch.Size([60, 1])\n",
      "Dataset created with X: torch.Size([60, 10]), Y: torch.Size([60, 1])\n",
      "X_values created with dimensions torch.Size([30, 10])\n",
      "Y_values created with dimensions torch.Size([30, 1])\n",
      "Dataset created with X: torch.Size([30, 10]), Y: torch.Size([30, 1])\n",
      "Iteration 10: Train Loss: 0.7182, Val Loss: 0.7797, Weights: ['-0.1707', '-0.5499', '0.7918', '0.4878', '0.8143', '0.3025', '0.7296', '-1.1190', '2.2569', '0.7613']\n",
      "Iteration 20: Train Loss: 0.7121, Val Loss: 0.7717, Weights: ['-0.1845', '-0.5485', '0.7783', '0.5006', '0.8041', '0.2792', '0.7257', '-1.1271', '2.2447', '0.7485']\n",
      "Iteration 30: Train Loss: 0.7061, Val Loss: 0.7640, Weights: ['-0.1982', '-0.5470', '0.7650', '0.5134', '0.7941', '0.2562', '0.7218', '-1.1351', '2.2325', '0.7358']\n",
      "Iteration 40: Train Loss: 0.7002, Val Loss: 0.7563, Weights: ['-0.2116', '-0.5456', '0.7519', '0.5260', '0.7842', '0.2335', '0.7179', '-1.1429', '2.2203', '0.7232']\n",
      "Iteration 50: Train Loss: 0.6944, Val Loss: 0.7488, Weights: ['-0.2250', '-0.5443', '0.7389', '0.5385', '0.7744', '0.2110', '0.7140', '-1.1505', '2.2081', '0.7107']\n",
      "Iteration 60: Train Loss: 0.6888, Val Loss: 0.7414, Weights: ['-0.2381', '-0.5430', '0.7260', '0.5509', '0.7648', '0.1888', '0.7101', '-1.1580', '2.1960', '0.6983']\n",
      "Iteration 70: Train Loss: 0.6833, Val Loss: 0.7342, Weights: ['-0.2511', '-0.5418', '0.7134', '0.5631', '0.7553', '0.1669', '0.7063', '-1.1653', '2.1839', '0.6861']\n",
      "Iteration 80: Train Loss: 0.6779, Val Loss: 0.7271, Weights: ['-0.2640', '-0.5406', '0.7009', '0.5752', '0.7460', '0.1452', '0.7024', '-1.1724', '2.1718', '0.6739']\n",
      "Iteration 90: Train Loss: 0.6726, Val Loss: 0.7201, Weights: ['-0.2766', '-0.5394', '0.6885', '0.5872', '0.7368', '0.1238', '0.6986', '-1.1793', '2.1598', '0.6619']\n",
      "Iteration 100: Train Loss: 0.6675, Val Loss: 0.7133, Weights: ['-0.2892', '-0.5383', '0.6763', '0.5991', '0.7277', '0.1027', '0.6948', '-1.1861', '2.1478', '0.6500']\n",
      "Iteration 110: Train Loss: 0.6625, Val Loss: 0.7066, Weights: ['-0.3016', '-0.5372', '0.6643', '0.6109', '0.7187', '0.0818', '0.6910', '-1.1927', '2.1359', '0.6382']\n",
      "Iteration 120: Train Loss: 0.6575, Val Loss: 0.7000, Weights: ['-0.3138', '-0.5362', '0.6525', '0.6225', '0.7100', '0.0612', '0.6872', '-1.1992', '2.1240', '0.6265']\n",
      "Iteration 130: Train Loss: 0.6528, Val Loss: 0.6936, Weights: ['-0.3259', '-0.5353', '0.6408', '0.6340', '0.7013', '0.0409', '0.6834', '-1.2055', '2.1121', '0.6150']\n",
      "Iteration 140: Train Loss: 0.6481, Val Loss: 0.6873, Weights: ['-0.3379', '-0.5344', '0.6292', '0.6454', '0.6928', '0.0208', '0.6797', '-1.2116', '2.1004', '0.6036']\n",
      "Iteration 150: Train Loss: 0.6435, Val Loss: 0.6811, Weights: ['-0.3497', '-0.5335', '0.6179', '0.6566', '0.6844', '0.0011', '0.6759', '-1.2176', '2.0886', '0.5922']\n",
      "Iteration 160: Train Loss: 0.6390, Val Loss: 0.6750, Weights: ['-0.3614', '-0.5327', '0.6067', '0.6678', '0.6762', '-0.0185', '0.6722', '-1.2235', '2.0769', '0.5811']\n",
      "Iteration 170: Train Loss: 0.6347, Val Loss: 0.6691, Weights: ['-0.3729', '-0.5319', '0.5956', '0.6788', '0.6682', '-0.0377', '0.6685', '-1.2292', '2.0653', '0.5700']\n",
      "Iteration 180: Train Loss: 0.6304, Val Loss: 0.6633, Weights: ['-0.3844', '-0.5312', '0.5848', '0.6897', '0.6602', '-0.0567', '0.6649', '-1.2348', '2.0537', '0.5590']\n",
      "Iteration 190: Train Loss: 0.6263, Val Loss: 0.6577, Weights: ['-0.3956', '-0.5305', '0.5740', '0.7005', '0.6525', '-0.0754', '0.6612', '-1.2402', '2.0422', '0.5482']\n",
      "Iteration 200: Train Loss: 0.6222, Val Loss: 0.6521, Weights: ['-0.4068', '-0.5299', '0.5635', '0.7111', '0.6448', '-0.0939', '0.6576', '-1.2455', '2.0307', '0.5375']\n",
      "Validation Log Loss: 0.0813\n",
      "\n",
      "Scratch Model Test Loss: 0.5691\n",
      "Mean Squared Error (MSE) between test predictions: 0.0932\n",
      "Scratch Model Test Accuracy: 0.8000\n",
      "Scikit-learn Model Test Accuracy: 0.5178\n"
     ]
    }
   ],
   "source": [
    "# Class for X values\n",
    "class X_values:\n",
    "    def __init__(self, dataset):\n",
    "        self.feature_dim = dataset.shape[1]\n",
    "        self.data_size = dataset.shape[0]\n",
    "        self.tensor = torch.tensor(dataset, dtype=torch.float32)\n",
    "        print(f\"X_values created with dimensions {self.tensor.shape}\")\n",
    "\n",
    "class Y_values:\n",
    "    def __init__(self, targets):\n",
    "        self.feature_dim = targets.shape[0]\n",
    "        self.tensor = torch.tensor(targets, dtype=torch.float32).view(-1, 1)\n",
    "        print(f\"Y_values created with dimensions {self.tensor.shape}\")\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, x_values, y_values):\n",
    "        self.x_tensor = x_values.tensor\n",
    "        self.y_tensor = y_values.tensor\n",
    "\n",
    "        if self.x_tensor.shape[0] != self.y_tensor.shape[0]:\n",
    "            raise ValueError(\"Mismatch between X and Y dimensions!\")\n",
    "        \n",
    "        self.feature_dim = x_values.feature_dim\n",
    "        self.data_size = x_values.data_size\n",
    "        print(f\"Dataset created with X: {self.x_tensor.shape}, Y: {self.y_tensor.shape}\")\n",
    "\n",
    "def split_dataset(dataset, train_rate, val_rate, test_rate):\n",
    "    if abs(train_rate + val_rate + test_rate - 1.0) > 1e-6:\n",
    "        raise ValueError(\"Split rates must sum to 1.\")\n",
    "\n",
    "    total_size = dataset.x_tensor.shape[0]\n",
    "    train_size = int(total_size * train_rate)\n",
    "    val_size = int(total_size * val_rate)\n",
    "\n",
    "    indices = torch.randperm(total_size)\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "\n",
    "    x_train, y_train = dataset.x_tensor[train_indices], dataset.y_tensor[train_indices]\n",
    "    x_val, y_val = dataset.x_tensor[val_indices], dataset.y_tensor[val_indices]\n",
    "    x_test, y_test = dataset.x_tensor[test_indices], dataset.y_tensor[test_indices]\n",
    "\n",
    "    train_dataset = Dataset(X_values(x_train.numpy()), Y_values(y_train.numpy()))\n",
    "    val_dataset = Dataset(X_values(x_val.numpy()), Y_values(y_val.numpy()))\n",
    "    test_dataset = Dataset(X_values(x_test.numpy()), Y_values(y_test.numpy()))\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Fix calculation functions\n",
    "def calculate_loss(x_tensor, y_tensor, weights):\n",
    "    logits = torch.matmul(x_tensor, weights)\n",
    "    loss = torch.mean(torch.log(1 + torch.exp(-y_tensor * logits)))\n",
    "    return loss\n",
    "\n",
    "def calculate_gradient(x_tensor, y_tensor, weights):\n",
    "    logits = torch.matmul(x_tensor, weights)\n",
    "    sigmoid = 1 / (1 + torch.exp(-logits))  # Sigmoid of the logits\n",
    "    gradient = (1 / x_tensor.shape[0]) * torch.matmul(x_tensor.T, sigmoid - y_tensor)\n",
    "    return gradient\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Logistic regression implementation\n",
    "def logistic_regression_train(train_dataset, val_dataset, iter_num, lr):\n",
    "    # Initialize weights randomly\n",
    "    weights = torch.randn((train_dataset.x_tensor.shape[1], 1), requires_grad=True)\n",
    "    \n",
    "    for i in range(iter_num):\n",
    "        # Training step\n",
    "        train_loss = calculate_loss(train_dataset.x_tensor, train_dataset.y_tensor, weights)\n",
    "        train_gradient = calculate_gradient(train_dataset.x_tensor, train_dataset.y_tensor, weights)\n",
    "        \n",
    "        # Update weights\n",
    "        with torch.no_grad():\n",
    "            weights -= lr * train_gradient\n",
    "        \n",
    "        # Validation step (no gradient computation needed)\n",
    "        with torch.no_grad():\n",
    "            val_loss = calculate_loss(val_dataset.x_tensor, val_dataset.y_tensor, weights)\n",
    "        \n",
    "        # Print iteration details\n",
    "        if ((i+1) % 10 == 0):\n",
    "            print(f\"Iteration {i + 1}: Train Loss: {train_loss.item():.4f}, \"f\"Val Loss: {val_loss.item():.4f}, \"f\"Weights: {[f'{w:.4f}' for w in weights.view(-1).tolist()]}\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "def logistic_regression_test(test_dataset, weights):\n",
    "    data_size = test_dataset.data_size\n",
    "    print(f\"Test Loss: {calculate_loss(test_dataset.x_tensor, test_dataset.y_tensor, weights)}\")\n",
    "\n",
    "    \n",
    "def logistic_regression_sklearn(train_dataset, val_dataset):\n",
    "    # Initialize the scikit-learn logistic regression model\n",
    "    model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "    # Convert tensors to numpy arrays for scikit-learn compatibility\n",
    "    x_train = train_dataset.x_tensor.numpy()\n",
    "    y_train = train_dataset.y_tensor.numpy().ravel()\n",
    "\n",
    "    x_val = val_dataset.x_tensor.numpy()\n",
    "    y_val = val_dataset.y_tensor.numpy().ravel()\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set using log loss\n",
    "    val_preds = model.predict_proba(x_val)[:, 1]\n",
    "    val_loss = log_loss(y_val, val_preds)\n",
    "    print(f\"Validation Log Loss: {val_loss:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "def compare_models(scratch_weights, sklearn_model, val_dataset):\n",
    "    # Predictions from scratch model\n",
    "    scratch_logits = torch.matmul(val_dataset.x_tensor, scratch_weights)\n",
    "    scratch_probs = 1 / (1 + torch.exp(-scratch_logits))\n",
    "    \n",
    "    # Predictions from Scikit-learn model\n",
    "    sklearn_probs = sklearn_model.predict_proba(val_dataset.x_tensor.numpy())[:, 1]  # Get probabilities for class 1\n",
    "\n",
    "    # Compute mean squared error (MSE) between predictions\n",
    "    mse = mean_squared_error(scratch_probs.detach().numpy(), sklearn_probs)\n",
    "    print(f\"Mean Squared Error (MSE) between predictions: {mse:.4f}\")\n",
    "\n",
    "    # Optionally, compare validation losses\n",
    "    scratch_loss = calculate_loss(val_dataset.x_tensor, val_dataset.y_tensor, scratch_weights).item()\n",
    "    sklearn_loss = -sklearn_model.score(val_dataset.x_tensor.numpy(), val_dataset.y_tensor.numpy())  # Negative accuracy\n",
    "    print(f\"Scratch Model Loss: {scratch_loss:.4f}\")\n",
    "    print(f\"Scikit-learn Loss (negative accuracy): {sklearn_loss:.4f}\")\n",
    "\n",
    "def compare_test_results(scratch_weights, sklearn_model, test_dataset):\n",
    "    # Scratch model test loss\n",
    "    scratch_loss = calculate_loss(test_dataset.x_tensor, test_dataset.y_tensor, scratch_weights).item()\n",
    "    print(f\"Scratch Model Test Loss: {scratch_loss:.4f}\")\n",
    "\n",
    "    # Predictions from scratch model\n",
    "    scratch_logits = torch.matmul(test_dataset.x_tensor, scratch_weights)\n",
    "    scratch_probs = 1 / (1 + torch.exp(-scratch_logits))\n",
    "\n",
    "    # Predictions from Scikit-learn model\n",
    "    sklearn_probs = sklearn_model.predict_proba(test_dataset.x_tensor.numpy())[:, 1]  # Get probabilities for class 1\n",
    "\n",
    "    # Compute mean squared error (MSE) between predictions\n",
    "    mse = mean_squared_error(scratch_probs.detach().numpy(), sklearn_probs)\n",
    "    print(f\"Mean Squared Error (MSE) between test predictions: {mse:.4f}\")\n",
    "\n",
    "    # Optionally, compare accuracies\n",
    "    scratch_preds = (scratch_probs > 0.5).float()\n",
    "    sklearn_preds = (sklearn_probs > 0.5).astype(np.float32)\n",
    "    \n",
    "    scratch_accuracy = (scratch_preds == test_dataset.y_tensor).float().mean().item()\n",
    "    sklearn_accuracy = (sklearn_preds == test_dataset.y_tensor.numpy()).mean()\n",
    "\n",
    "    print(f\"Scratch Model Test Accuracy: {scratch_accuracy:.4f}\")\n",
    "    print(f\"Scikit-learn Model Test Accuracy: {sklearn_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    \n",
    "def generate_synthetic_data(num_samples=300, num_features=10, seed=42):\n",
    "    np.random.seed(seed)  # For reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Generate random feature matrix (Gaussian distribution)\n",
    "    X = np.random.randn(num_samples, num_features)\n",
    "\n",
    "    # Define true weights and bias\n",
    "    true_weights = np.random.randn(num_features)\n",
    "    true_bias = np.random.randn()\n",
    "\n",
    "    # Compute logits (linear combination of features and weights)\n",
    "    logits = X @ true_weights + true_bias\n",
    "\n",
    "    # Apply sigmoid function to get probabilities\n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "    # Generate binary targets based on probabilities\n",
    "    y = (probs > 0.5).astype(np.float32)  # Threshold at 0.5\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = generate_synthetic_data()\n",
    "x_values = X_values(X)\n",
    "y_values = Y_values(y)\n",
    "dataset = Dataset(x_values, y_values)\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset, test_dataset = split_dataset(dataset, train_rate=0.7, val_rate=0.2, test_rate=0.1)\n",
    "\n",
    "# Train scratch model\n",
    "scratch_weights = logistic_regression_train(train_dataset, val_dataset, iter_num=200, lr=0.01)\n",
    "\n",
    "# Test scratch model\n",
    "#logistic_regression_test(test_dataset, scratch_weights)\n",
    "\n",
    "# Train scikit-learn model\n",
    "sklearn_model = logistic_regression_sklearn(train_dataset, val_dataset)\n",
    "\n",
    "# Test scikit-learn model\n",
    "\n",
    "# Compare the two models\n",
    "#compare_models(scratch_weights, sklearn_model, val_dataset)\n",
    "compare_test_results(scratch_weights, sklearn_model, test_dataset)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4aba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336185b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b3fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284126ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef3749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544febef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
